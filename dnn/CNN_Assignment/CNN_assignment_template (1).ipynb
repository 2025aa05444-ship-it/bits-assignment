{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3561c56",
   "metadata": {
    "id": "c3561c56"
   },
   "source": [
    "# DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
    "\n",
    "## Convolutional Neural Networks: Custom Implementation vs Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7be6ad",
   "metadata": {
    "id": "fb7be6ad"
   },
   "source": [
    "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
    "\n",
    "BITS ID: [2025AA05444]\n",
    "\n",
    "Name: [PRASAD SHIVAJI KULKARNI]\n",
    "\n",
    "Email: [2025aa05444@wilp.bits-pilani.ac.in]\n",
    "\n",
    "Date: [08/02/2026]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afa82e11",
   "metadata": {
    "id": "afa82e11"
   },
   "source": [
    "\"\"\"\n",
    "ASSIGNMENT OVERVIEW\n",
    "\n",
    "This assignment requires you to implement and compare two CNN approaches for\n",
    "image classification:\n",
    "1. Custom CNN architecture using Keras/PyTorch\n",
    "2. Transfer Learning using pre-trained models (ResNet/VGG)\n",
    "\n",
    "Learning Objectives:\n",
    "- Design CNN architectures with Global Average Pooling\n",
    "- Apply transfer learning with pre-trained models\n",
    "- Compare custom vs pre-trained model performance\n",
    "- Use industry-standard deep learning frameworks\n",
    "\n",
    "IMPORTANT: Global Average Pooling (GAP) is MANDATORY for both models.\n",
    "DO NOT use Flatten + Dense layers in the final architecture.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "49ca00eb",
   "metadata": {
    "id": "49ca00eb"
   },
   "source": [
    "\"\"\"\n",
    " IMPORTANT SUBMISSION REQUIREMENTS - STRICTLY ENFORCED\n",
    "\n",
    "1. FILENAME FORMAT: <BITS_ID>_cnn_assignment.ipynb\n",
    "   Example: 2025AA05036_cnn_assignment.ipynb\n",
    "    Wrong filename = Automatic 0 marks\n",
    "\n",
    "2. STUDENT INFORMATION MUST MATCH:\n",
    "    BITS ID in filename = BITS ID in notebook (above)\n",
    "    Name in folder = Name in notebook (above)\n",
    "    Mismatch = 0 marks\n",
    "\n",
    "3. EXECUTE ALL CELLS BEFORE SUBMISSION:\n",
    "   - Run: Kernel \u2192 Restart & Run All\n",
    "   - Verify all outputs are visible\n",
    "    No outputs = 0 marks\n",
    "\n",
    "4. FILE INTEGRITY:\n",
    "   - Ensure notebook opens without errors\n",
    "   - Check for corrupted cells\n",
    "    Corrupted file = 0 marks\n",
    "\n",
    "5. GLOBAL AVERAGE POOLING (GAP) MANDATORY:\n",
    "   - Both custom CNN and transfer learning must use GAP\n",
    "   - DO NOT use Flatten + Dense layers\n",
    "    Using Flatten+Dense = 0 marks for that model\n",
    "\n",
    "6. DATASET REQUIREMENTS:\n",
    "   - Minimum 500 images per class\n",
    "   - Train/test split: 90/10 OR 85/15\n",
    "   - 2-20 classes\n",
    "\n",
    "7. USE KERAS OR PYTORCH:\n",
    "   - Use standard model.fit() or training loops\n",
    "   - Do NOT implement convolution from scratch\n",
    "\n",
    "8. FILE SUBMISSION:\n",
    "   - Submit ONLY the .ipynb file\n",
    "   - NO zip files, NO separate data files, NO separate image files\n",
    "   - All code and outputs must be in the notebook\n",
    "   - Only one submission attempt allowed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be209f24",
   "metadata": {
    "id": "be209f24"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cbf85",
   "metadata": {
    "id": "506cbf85"
   },
   "outputs": [],
   "source": [
    "# Deep learning frameworks (choose Keras or PyTorch)\n",
    "# For image processing\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8162fad",
   "metadata": {
    "id": "d8162fad"
   },
   "source": [
    "\"\"\"\n",
    "PART 1: DATASET LOADING AND EXPLORATION (Informational)\n",
    "\n",
    "Instructions:\n",
    "1. Choose ONE dataset from the allowed list\n",
    "2. Load and explore the data\n",
    "3. Fill in ALL required metadata fields below\n",
    "4. Provide justification for your primary metric choice\n",
    "\n",
    "ALLOWED DATASETS:\n",
    "- Cats vs Dogs (2 classes)\n",
    "- Food-101 subset (10-20 classes)\n",
    "- Plant Disease (3-5 classes)\n",
    "- Medical Images (2-3 classes)\n",
    "- Custom dataset (with IC approval, min 500 images per class)\n",
    "\n",
    "REQUIRED OUTPUT:\n",
    "- Print all metadata fields\n",
    "- Brief EDA with visualizations\n",
    "- Data distribution analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "id": "972a1a99",
   "metadata": {
    "id": "972a1a99"
   },
   "source": [
    "# Download Cats and Dogs dataset\n",
    "dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=dataset_url, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e736527",
   "metadata": {
    "id": "6e736527"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"Cats vs Dogs (Filtered)\"\n",
    "dataset_source = \"TensorFlow Datasets / Microsoft\"\n",
    "n_samples = 3000\n",
    "n_classes = len(class_names)\n",
    "samples_per_class = \"1000 per class (balanced)\"\n",
    "image_shape = [160, 160, 3]\n",
    "problem_type = \"classification\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a03e43",
   "metadata": {
    "id": "88a03e43"
   },
   "outputs": [],
   "source": [
    "primary_metric = \"accuracy\"\n",
    "metric_justification = \"Accuracy is chosen because the dataset is balanced.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23501291",
   "metadata": {
    "id": "23501291"
   },
   "outputs": [],
   "source": [
    "print(\"DATASET INFORMATION\")\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Total Samples: {n_samples}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Samples per Class: {samples_per_class}\")\n",
    "print(f\"Image Shape: {image_shape}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")\n",
    "print(f\"Metric Justification: {metric_justification}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d410ae6",
   "metadata": {
    "id": "1d410ae6"
   },
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(class_names, [1000, 1000])\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1059bd58",
   "metadata": {
    "id": "1059bd58"
   },
   "source": [
    "### 1.3 Data Preprocessing\n",
    "- TODO: Resize images to consistent size\n",
    "- TODO: Normalize pixel values\n",
    "- TODO: Split into train/test (90/10 or 85/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff05ae",
   "metadata": {
    "id": "c9ff05ae"
   },
   "outputs": [],
   "source": [
    "train_test_ratio = \"67/33 (approx)\"\n",
    "train_samples = 2000\n",
    "test_samples = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae8952",
   "metadata": {
    "id": "c3ae8952"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
    "print(f\"Training Samples: {train_samples}\")\n",
    "print(f\"Test Samples: {test_samples}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c27ab45a",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "c27ab45a"
   },
   "source": [
    "\"\"\"\n",
    "PART 2: CUSTOM CNN IMPLEMENTATION (5 MARKS)\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Build CNN using Keras/PyTorch layers\n",
    "- Architecture must include:\n",
    "  * Conv2D layers (at least 2)\n",
    "  * Pooling layers (MaxPool or AvgPool)\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Output layer (Softmax for multi-class)\n",
    "- Use model.compile() and model.fit() (Keras) OR standard PyTorch training\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "PROHIBITED:\n",
    "- Using Flatten + Dense layers instead of GAP\n",
    "- Implementing convolution from scratch\n",
    "\n",
    "GRADING:\n",
    "- Architecture design with GAP: 2 marks\n",
    "- Model properly compiled/configured: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a1426",
   "metadata": {
    "id": "709a1426"
   },
   "source": [
    "### 2.1 Custom CNN Architecture Design\n",
    "- TODO: Define your CNN architecture\n",
    "- TODO: Ensure Global Average Pooling is included (MANDATORY)\n",
    "- TODO: Use Conv2D, MaxPooling2D/AvgPooling2D, GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b21d7",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "a42b21d7"
   },
   "outputs": [],
   "source": [
    "def build_custom_cnn(input_shape, n_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    # Global Average Pooling (MANDATORY)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid') if n_classes == 2 else layers.Dense(n_classes, activation='softmax')\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c3ff6",
   "metadata": {
    "id": "169c3ff6"
   },
   "outputs": [],
   "source": [
    "# TODO: Create model instance\n",
    "custom_cnn = build_custom_cnn(image_shape, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18622a9",
   "metadata": {
    "id": "c18622a9"
   },
   "outputs": [],
   "source": [
    "custom_cnn.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy() if n_classes==2 else 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ff01f",
   "metadata": {
    "id": "e79ff01f"
   },
   "source": [
    "### 2.2 Train Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017613c",
   "metadata": {
    "id": "1017613c"
   },
   "outputs": [],
   "source": [
    "print(\"\\nCUSTOM CNN TRAINING\")\n",
    "# Track training time\n",
    "custom_cnn_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e274ecb",
   "metadata": {
    "id": "3e274ecb"
   },
   "outputs": [],
   "source": [
    "history_custom = custom_cnn.fit(train_dataset,\n",
    "                                validation_data=validation_dataset,\n",
    "                                epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0db0e",
   "metadata": {
    "id": "42e0db0e"
   },
   "outputs": [],
   "source": [
    "custom_cnn_training_time = time.time() - custom_cnn_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cf308",
   "metadata": {
    "id": "748cf308"
   },
   "outputs": [],
   "source": [
    "custom_cnn_initial_loss = history_custom.history['loss'][0]\n",
    "custom_cnn_final_loss = history_custom.history['loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca325a3",
   "metadata": {
    "id": "fca325a3"
   },
   "outputs": [],
   "source": [
    "print(f\"Training completed in {custom_cnn_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {custom_cnn_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {custom_cnn_final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81ab02",
   "metadata": {
    "id": "7c81ab02"
   },
   "outputs": [],
   "source": [
    "print(\"\\nCUSTOM CNN EVALUATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0090d1",
   "metadata": {
    "id": "db0090d1"
   },
   "source": [
    "### 2.3 Evaluate Custom CNN\n",
    "- TODO: Make predictions on test set\n",
    "- TODO: Calculate all 4 required metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7796b66",
   "metadata": {
    "id": "e7796b66"
   },
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in test_dataset:\n",
    "    preds = custom_cnn.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend((preds > 0.5).astype(int).flatten() if n_classes==2 else np.argmax(preds, axis=1))\n",
    "\n",
    "custom_cnn_accuracy = accuracy_score(y_true, y_pred)\n",
    "custom_cnn_precision = precision_score(y_true, y_pred, average='binary' if n_classes==2 else 'macro')\n",
    "custom_cnn_recall = recall_score(y_true, y_pred, average='binary' if n_classes==2 else 'macro')\n",
    "custom_cnn_f1 = f1_score(y_true, y_pred, average='binary' if n_classes==2 else 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701dd335",
   "metadata": {
    "id": "701dd335"
   },
   "outputs": [],
   "source": [
    "print(\"\\nCustom CNN Performance:\")\n",
    "print(f\"Accuracy:  {custom_cnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {custom_cnn_precision:.4f}\")\n",
    "print(f\"Recall:    {custom_cnn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {custom_cnn_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "1eac1b9f",
   "metadata": {
    "id": "1eac1b9f"
   },
   "source": [
    "acc = history_custom.history['accuracy']\n",
    "val_acc = history_custom.history['val_accuracy']\n",
    "loss = history_custom.history['loss']\n",
    "val_loss = history_custom.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "id": "4ed9649e",
   "metadata": {
    "id": "4ed9649e"
   },
   "source": [
    "\"\"\"\n",
    "PART 3: TRANSFER LEARNING IMPLEMENTATION (5 MARKS)\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use pre-trained model: ResNet18/ResNet50 OR VGG16/VGG19\n",
    "- Freeze base layers (feature extractor)\n",
    "- Replace final layers with:\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Custom classification head\n",
    "- Fine-tune on your dataset\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "GRADING:\n",
    "- Valid base model with frozen layers: 2 marks\n",
    "- GAP + custom head properly implemented: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c6095",
   "metadata": {
    "id": "f11c6095"
   },
   "source": [
    "### 3.1 Load Pre-trained Model and Modify Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b730caa",
   "metadata": {
    "id": "5b730caa"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING IMPLEMENTATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77826188",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "77826188"
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"ResNet50\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80ccd2",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "da80ccd2"
   },
   "outputs": [],
   "source": [
    "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(input_shape=input_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x) if n_classes == 2 else layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy' if n_classes==2 else 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcd14a",
   "metadata": {
    "id": "bbfcd14a"
   },
   "outputs": [],
   "source": [
    "# TODO: Create transfer learning model\n",
    "transfer_model = build_transfer_learning_model(pretrained_model_name, image_shape, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628ff28",
   "metadata": {
    "id": "9628ff28"
   },
   "outputs": [],
   "source": [
    "frozen_layers = len(transfer_model.layers[1].layers) # Base model layers\n",
    "trainable_layers = len(transfer_model.layers) - 1 # Top layers\n",
    "total_parameters = transfer_model.count_params()\n",
    "trainable_parameters = sum([w.shape.num_elements() for w in transfer_model.trainable_weights])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16425da9",
   "metadata": {
    "id": "16425da9"
   },
   "outputs": [],
   "source": [
    "print(f\"Base Model: {pretrained_model_name}\")\n",
    "print(f\"Frozen Layers: {frozen_layers}\")\n",
    "print(f\"Trainable Layers: {trainable_layers}\")\n",
    "print(f\"Total Parameters: {total_parameters:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters:,}\")\n",
    "print(f\"Using Global Average Pooling: YES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007d532",
   "metadata": {
    "id": "6007d532"
   },
   "source": [
    "### 3.2 Train Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae60dc",
   "metadata": {
    "id": "f8ae60dc"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTraining Transfer Learning Model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1508f",
   "metadata": {
    "id": "07e1508f"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "tl_learning_rate = 0.001\n",
    "tl_epochs = 10\n",
    "tl_batch_size = 32\n",
    "tl_optimizer = \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfde0a9",
   "metadata": {
    "id": "7bfde0a9"
   },
   "outputs": [],
   "source": [
    "# Track training time\n",
    "tl_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80090240",
   "metadata": {
    "id": "80090240"
   },
   "outputs": [],
   "source": [
    "history_tl = transfer_model.fit(train_dataset,\n",
    "                                validation_data=validation_dataset,\n",
    "                                epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1df61",
   "metadata": {
    "id": "1fb1df61"
   },
   "outputs": [],
   "source": [
    "tl_training_time = time.time() - tl_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d64ec",
   "metadata": {
    "id": "de1d64ec"
   },
   "outputs": [],
   "source": [
    "tl_initial_loss = history_tl.history['loss'][0]\n",
    "tl_final_loss = history_tl.history['loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00548043",
   "metadata": {
    "id": "00548043"
   },
   "outputs": [],
   "source": [
    "print(f\"Training completed in {tl_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {tl_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {tl_final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a01fcf",
   "metadata": {
    "id": "67a01fcf"
   },
   "source": [
    "### 3.3 Evaluate Transfer Learning Model\n",
    "- TODO: Make predictions on test set\n",
    "- TODO: Calculate all 4 required metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb6ab7",
   "metadata": {
    "id": "dfbb6ab7"
   },
   "outputs": [],
   "source": [
    "y_true_tl = []\n",
    "y_pred_tl = []\n",
    "for images, labels in test_dataset:\n",
    "    preds = transfer_model.predict(images, verbose=0)\n",
    "    y_true_tl.extend(labels.numpy())\n",
    "    y_pred_tl.extend((preds > 0.5).astype(int).flatten() if n_classes==2 else np.argmax(preds, axis=1))\n",
    "\n",
    "tl_accuracy = accuracy_score(y_true_tl, y_pred_tl)\n",
    "tl_precision = precision_score(y_true_tl, y_pred_tl, average='binary' if n_classes==2 else 'macro')\n",
    "tl_recall = recall_score(y_true_tl, y_pred_tl, average='binary' if n_classes==2 else 'macro')\n",
    "tl_f1 = f1_score(y_true_tl, y_pred_tl, average='binary' if n_classes==2 else 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7266a",
   "metadata": {
    "id": "49c7266a"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTransfer Learning Performance:\")\n",
    "print(f\"Accuracy:  {tl_accuracy:.4f}\")\n",
    "print(f\"Precision: {tl_precision:.4f}\")\n",
    "print(f\"Recall:    {tl_recall:.4f}\")\n",
    "print(f\"F1-Score:  {tl_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "795e7279",
   "metadata": {
    "id": "795e7279"
   },
   "source": [
    "acc = history_tl.history['accuracy']\n",
    "val_acc = history_tl.history['val_accuracy']\n",
    "loss = history_tl.history['loss']\n",
    "val_loss = history_tl.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('TL Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('TL Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_true_tl, y_pred_tl)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('TL Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "id": "dee2512c",
   "metadata": {
    "id": "dee2512c"
   },
   "source": [
    "\"\"\"\n",
    "PART 4: MODEL COMPARISON AND VISUALIZATION (Informational)\n",
    "\n",
    "Compare both models on:\n",
    "- Performance metrics\n",
    "- Training time\n",
    "- Model complexity\n",
    "- Convergence behavior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a4ea0",
   "metadata": {
    "id": "8e9a4ea0"
   },
   "source": [
    "### 4.1 Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51221e",
   "metadata": {
    "id": "8e51221e"
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Parameters'],\n",
    "    'Custom CNN': [\n",
    "        custom_cnn_accuracy,\n",
    "        custom_cnn_precision,\n",
    "        custom_cnn_recall,\n",
    "        custom_cnn_f1,\n",
    "        custom_cnn_training_time,\n",
    "        custom_cnn.count_params()\n",
    "    ],\n",
    "    'Transfer Learning': [\n",
    "        tl_accuracy,\n",
    "        tl_precision,\n",
    "        tl_recall,\n",
    "        tl_f1,\n",
    "        tl_training_time,\n",
    "        trainable_parameters\n",
    "    ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56dde6",
   "metadata": {
    "id": "5d56dde6"
   },
   "outputs": [],
   "source": [
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffd6002a",
   "metadata": {
    "id": "ffd6002a"
   },
   "source": [
    "comparison_df.set_index('Metric')[['Custom CNN', 'Transfer Learning']].iloc[:4].plot(kind='bar')\n",
    "plt.title('Performance Comparison')\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "raw",
   "id": "56d56632",
   "metadata": {
    "id": "56d56632"
   },
   "source": [
    "\"\"\"\n",
    "PART 5: ANALYSIS (2 MARKS)\n",
    "\n",
    "REQUIRED:\n",
    "- Write MAXIMUM 200 words (guideline - no marks deduction if exceeded)\n",
    "- Address key topics with depth\n",
    "\n",
    "GRADING (Quality-based):\n",
    "- Covers 5+ key topics with deep understanding: 2 marks\n",
    "- Covers 3-4 key topics with good understanding: 1 mark\n",
    "- Covers <3 key topics or superficial: 0 marks\n",
    "\n",
    "Key Topics:\n",
    "1. Performance comparison with specific metrics\n",
    "2. Pre-training vs training from scratch impact\n",
    "3. GAP effect on performance/overfitting\n",
    "4. Computational cost comparison\n",
    "5. Transfer learning insights\n",
    "6. Convergence behavior differences\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f373a",
   "metadata": {
    "id": "638f373a"
   },
   "outputs": [],
   "source": [
    "analysis_text = \"\"\"\n",
    "1. Performance: Transfer Learning (ResNet50) achieved higher accuracy and f1_score compared to the Custom CNN. Pre-trained weights provided a strong feature extractor.\n",
    "2. Pre-training Impact: Using pre-trained weights significantly faster convergence. The model started with high accuracy, whereas Custom CNN needed more epochs.\n",
    "3. GAP Effect: Global Average Pooling reduced parameters significantly compared to Flatten+Dense, preventing overfitting and reducing computational cost.\n",
    "4. Cost: Custom CNN is lightweight in parameters but takes longer to converge. TL has more parameters (in base) but trainable parameters are few, making fine-tuning fast.\n",
    "5. Insights: Transfer learning is superior for small datasets like this, leveraging learned features from ImageNet. Custom CNN requires more data/epochs to match performance.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f4b03",
   "metadata": {
    "id": "391f4b03"
   },
   "outputs": [],
   "source": [
    "# REQUIRED: Print analysis with word count\n",
    "print(\"ANALYSIS\")\n",
    "print(analysis_text)\n",
    "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
    "if len(analysis_text.split()) > 200:\n",
    "    print(\"  Warning: Analysis exceeds 200 words (guideline)\")\n",
    "else:\n",
    "    print(\" Analysis within word count guideline\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce05876e",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "ce05876e"
   },
   "source": [
    "\"\"\"\n",
    "PART 6: ASSIGNMENT RESULTS SUMMARY (REQUIRED FOR AUTO-GRADING)\n",
    "\n",
    "DO NOT MODIFY THE STRUCTURE BELOW\n",
    "This JSON output is used by the auto-grader\n",
    "Ensure all field names are EXACT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580f5ac",
   "metadata": {
    "lines_to_next_cell": 1,
    "id": "7580f5ac"
   },
   "outputs": [],
   "source": [
    "        'custom_cnn': {\n",
    "            'framework': framework_used,\n",
    "            'architecture': {\n",
    "                'conv_layers': 3,\n",
    "                'pooling_layers': 3,\n",
    "                'has_global_average_pooling': True,\n",
    "                'output_layer': 'sigmoid',\n",
    "                'total_parameters': custom_cnn.count_params()\n",
    "            },\n",
    "            'training_config': {\n",
    "                'learning_rate': 0.001,\n",
    "                'n_epochs': 15,\n",
    "                'batch_size': 32,\n",
    "                'optimizer': 'Adam',\n",
    "                'loss_function': 'binary_crossentropy'\n",
    "            },\n",
    "            'initial_loss': custom_cnn_initial_loss,\n",
    "            'final_loss': custom_cnn_final_loss,\n",
    "            'training_time_seconds': custom_cnn_training_time,\n",
    "            'accuracy': custom_cnn_accuracy,\n",
    "            'precision': custom_cnn_precision,\n",
    "            'recall': custom_cnn_recall,\n",
    "            'f1_score': custom_cnn_f1\n",
    "        },\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cec80",
   "metadata": {
    "id": "a94cec80"
   },
   "outputs": [],
   "source": [
    "# Generate and print results\n",
    "try:\n",
    "    assignment_results = get_assignment_results()\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(json.dumps(assignment_results, indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n  ERROR generating results: {str(e)}\")\n",
    "    print(\"Please ensure all variables are properly defined\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50657458",
   "metadata": {
    "id": "50657458"
   },
   "source": [
    "\"\"\"\n",
    "ENVIRONMENT VERIFICATION - SCREENSHOT REQUIRED\n",
    "\n",
    "IMPORTANT: Take a screenshot of your environment showing account details\n",
    "\n",
    "For Google Colab:\n",
    "- Click on your profile icon (top right)\n",
    "- Screenshot should show your email/account clearly\n",
    "- Include the entire Colab interface with notebook name visible\n",
    "\n",
    "For BITS Virtual Lab:\n",
    "- Screenshot showing your login credentials/account details\n",
    "- Include the entire interface with your username/session info visible\n",
    "\n",
    "Paste the screenshot below this cell or in a new markdown cell.\n",
    "This helps verify the work was done by you in your environment.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4747e6",
   "metadata": {
    "id": "5a4747e6"
   },
   "outputs": [],
   "source": [
    "# Display system information\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ae62c",
   "metadata": {
    "id": "6e5ae62c"
   },
   "outputs": [],
   "source": [
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"\\n  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
    "print(\"showing your account details in the cell below this one.\")\n",
    "\n",
    "# include the screen shot here"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e214cf5",
   "metadata": {
    "id": "7e214cf5"
   },
   "source": [
    "\"\"\"\n",
    "FINAL CHECKLIST - VERIFY BEFORE SUBMISSION\n",
    "\n",
    "\u25a1 Student information filled at the top (BITS ID, Name, Email)\n",
    "\u25a1 Filename is <BITS_ID>_cnn_assignment.ipynb\n",
    "\u25a1 All cells executed (Kernel \u2192 Restart & Run All)\n",
    "\u25a1 All outputs visible\n",
    "\u25a1 Custom CNN implemented with Global Average Pooling (NO Flatten+Dense)\n",
    "\u25a1 Transfer learning implemented with GAP\n",
    "\u25a1 Both models use Keras or PyTorch (NOT from scratch)\n",
    "\u25a1 Both models trained with loss tracking (initial_loss and final_loss)\n",
    "\u25a1 All 4 metrics calculated for both models\n",
    "\u25a1 Primary metric selected and justified\n",
    "\u25a1 Analysis written (quality matters, not just word count)\n",
    "\u25a1 Visualizations created\n",
    "\u25a1 Assignment results JSON printed at the end\n",
    "\u25a1 No execution errors in any cell\n",
    "\u25a1 File opens without corruption\n",
    "\u25a1 Submit ONLY .ipynb file (NO zip, NO data files, NO images)\n",
    "\u25a1 Only one submission attempt\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V5E1"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}